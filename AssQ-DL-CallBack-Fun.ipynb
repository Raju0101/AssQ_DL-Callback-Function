{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f81157d4-23d9-4fbf-bcee-8b548689c90c",
   "metadata": {},
   "source": [
    "## AssQ-DL-CallBack-Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a3364e-d297-47bc-a40c-475de9e27e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Install and load the latest versions of TensorFlow and Keras. Print their versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09129266-baf2-4000-8637-c0b18eacfac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers>=23.1.21\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorboard<2.14,>=2.13\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting keras<2.14,>=2.13.1\n",
      "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.21.8)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (65.5.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.33.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.15.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<=1.24.3,>=1.22 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.23.4)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.57.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-2.3.7-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.2/242.2 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.8/181.8 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.28.1)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.2/94.2 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (1.26.11)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.1)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, opt-einsum, markdown, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, rsa, requests-oauthlib, pyasn1-modules, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.1 flatbuffers-23.5.26 gast-0.4.0 google-auth-2.22.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.57.0 keras-2.13.1 libclang-16.0.6 markdown-3.4.4 opt-einsum-3.3.0 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.13.0 tensorboard-data-server-0.7.1 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow-io-gcs-filesystem-0.33.0 termcolor-2.3.0 werkzeug-2.3.7 wrapt-1.15.0\n",
      "Requirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (2.13.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow\n",
    "! pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a0fbc65-a526-41fd-bd80-51528c8e71fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-27 04:55:21.458199: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-27 04:55:21.556632: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-27 04:55:21.565188: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-27 04:55:23.804207: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.13.0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.api._v2.keras' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorFlow version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, tf\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeras version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__version__\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/lazy_loader.py:59\u001b[0m, in \u001b[0;36mLazyLoader.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[1;32m     58\u001b[0m   module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load()\n\u001b[0;32m---> 59\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.api._v2.keras' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec7aeba-8a0f-4e9a-b9f0-c5a5696176d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "To install the latest versions of TensorFlow and Keras, you can use the following\n",
    "pip commands in your terminal or command prompt:\n",
    "\n",
    "\n",
    "pip install tensorflow\n",
    "pip install keras\n",
    "After installation, you can verify the versions by running the following Python code:\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)\n",
    "\n",
    "Running this code should print out the versions of TensorFlow and Keras that you have installed.\n",
    "Keep in mind that the latest versions might change over time, so it's a good practice to check the \n",
    "official websites for any updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c1968b-5ac2-4f84-b6ee-ac4dd1ddd455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23090e7f-ecb2-4337-8639-680b186dd9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. Load the Wine Quality dataset and explore its dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77264c5f-d3ba-4e91-b4ba-066c84a1f909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 4898\n",
      "Number of columns: 12\n",
      "\n",
      "First few rows of the dataset:\n",
      "\n",
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.0              0.27         0.36            20.7      0.045   \n",
      "1            6.3              0.30         0.34             1.6      0.049   \n",
      "2            8.1              0.28         0.40             6.9      0.050   \n",
      "3            7.2              0.23         0.32             8.5      0.058   \n",
      "4            7.2              0.23         0.32             8.5      0.058   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
      "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
      "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
      "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
      "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      8.8        6  \n",
      "1      9.5        6  \n",
      "2     10.1        6  \n",
      "3      9.9        6  \n",
      "4      9.9        6  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "wine_data = pd.read_csv(url, sep=\";\")\n",
    "\n",
    "# Display the dimensions of the dataset\n",
    "rows, columns = wine_data.shape\n",
    "print(\"Number of rows:\", rows)\n",
    "print(\"Number of columns:\", columns)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"\\nFirst few rows of the dataset:\\n\")\n",
    "print(wine_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1e80ae-8852-445f-8455-1b2d033a6061",
   "metadata": {},
   "outputs": [],
   "source": [
    "the Wine Quality dataset is a commonly used dataset for classification and regression tasks.\n",
    "It's available in various formats, such as CSV. Here's how you can load and explore the\n",
    "dataset using Python and the pandas library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e887553-9628-473e-bd75-5ecf55f3244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "we're using the pandas library to load the Wine Quality dataset from the given URL, \n",
    "assuming it's the white wine version of the dataset. \n",
    "We then display the dimensions (number of rows and columns) of the dataset and show \n",
    "the first few rows to get a glimpse of its structure.\n",
    "\n",
    "Remember that the dataset might have changed or moved since my last knowledge update \n",
    "in September 2021, so ensure the URL is still valid and points to the correct dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dccfddb-ebbc-4459-9e15-511c71d6bb9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95ddef1-f303-4e9a-a6b0-9a68b24d5adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. Check for null values, identify categorical variables, and encode them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d7f43d4-840f-4dcd-9e15-563db587966d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in each column:\n",
      "\n",
      "fixed acidity           0\n",
      "volatile acidity        0\n",
      "citric acid             0\n",
      "residual sugar          0\n",
      "chlorides               0\n",
      "free sulfur dioxide     0\n",
      "total sulfur dioxide    0\n",
      "density                 0\n",
      "pH                      0\n",
      "sulphates               0\n",
      "alcohol                 0\n",
      "quality                 0\n",
      "dtype: int64\n",
      "\n",
      "Categorical columns:\n",
      "\n",
      "Index([], dtype='object')\n",
      "\n",
      "Updated dataset with encoded categorical variables:\n",
      "\n",
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.0              0.27         0.36            20.7      0.045   \n",
      "1            6.3              0.30         0.34             1.6      0.049   \n",
      "2            8.1              0.28         0.40             6.9      0.050   \n",
      "3            7.2              0.23         0.32             8.5      0.058   \n",
      "4            7.2              0.23         0.32             8.5      0.058   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
      "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
      "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
      "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
      "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      8.8        6  \n",
      "1      9.5        6  \n",
      "2     10.1        6  \n",
      "3      9.9        6  \n",
      "4      9.9        6  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "wine_data = pd.read_csv(url, sep=\";\")\n",
    "\n",
    "# Check for null values\n",
    "null_values = wine_data.isnull().sum()\n",
    "print(\"Null values in each column:\\n\")\n",
    "print(null_values)\n",
    "\n",
    "# Identify categorical variables\n",
    "categorical_columns = wine_data.select_dtypes(include=['object']).columns\n",
    "print(\"\\nCategorical columns:\\n\")\n",
    "print(categorical_columns)\n",
    "\n",
    "# Encode categorical variables using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "for col in categorical_columns:\n",
    "    wine_data[col] = label_encoder.fit_transform(wine_data[col])\n",
    "\n",
    "# Display the updated dataset\n",
    "print(\"\\nUpdated dataset with encoded categorical variables:\\n\")\n",
    "print(wine_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49518abb-2b3c-4265-a8f1-c90f84fd79b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, we first use the isnull().sum() method to check for null values in each column \n",
    "of the dataset. Then, we identify categorical columns by selecting columns with data types \n",
    "that are considered \"object\" (usually strings).\n",
    "\n",
    "We use the LabelEncoder from scikit-learn to encode the categorical variables. This replaces\n",
    "the categorical values with unique numerical values. Remember that LabelEncoder is suitable \n",
    "for ordinal categorical data, where there is some meaningful order. For nominal categorical \n",
    "data, one-hot encoding might be a better choice.\n",
    "\n",
    "Finally, we display the updated dataset with the encoded categorical variables. Note that\n",
    "this encoding approach might not be ideal for all types of categorical variables; in some \n",
    ", you might need to consider other encoding methods like one-hot encoding or target encoding\n",
    "based on the nature of your data and the machine learning algorithm you plan to use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6833d386-aa2d-4912-a3cc-81d537fb8902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed124f4b-c6ad-4b77-94c1-a14ce01e5528",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Separate the features and target variables from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6e1c4be-0f9e-44cc-98b1-a28264d94c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:\n",
      "\n",
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.0              0.27         0.36            20.7      0.045   \n",
      "1            6.3              0.30         0.34             1.6      0.049   \n",
      "2            8.1              0.28         0.40             6.9      0.050   \n",
      "3            7.2              0.23         0.32             8.5      0.058   \n",
      "4            7.2              0.23         0.32             8.5      0.058   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
      "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
      "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
      "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
      "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
      "\n",
      "   alcohol  \n",
      "0      8.8  \n",
      "1      9.5  \n",
      "2     10.1  \n",
      "3      9.9  \n",
      "4      9.9  \n",
      "\n",
      "Target:\n",
      "\n",
      "0    6\n",
      "1    6\n",
      "2    6\n",
      "3    6\n",
      "4    6\n",
      "Name: quality, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "wine_data = pd.read_csv(url, sep=\";\")\n",
    "\n",
    "# Separate features and target\n",
    "features = wine_data.drop(\"quality\", axis=1)  # Drop the 'quality' column\n",
    "target = wine_data[\"quality\"]\n",
    "\n",
    "# Display the first few rows of features and target\n",
    "print(\"Features:\\n\")\n",
    "print(features.head())\n",
    "print(\"\\nTarget:\\n\")\n",
    "print(target.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc5cfe-3469-4b35-bcad-fad92eaa02c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, the features DataFrame contains all columns except the \"quality\" column,\n",
    "which is the target variable. The target Series contains only the \"quality\" column.\n",
    "This separation allows you to work with the input features and target separately for analysis,\n",
    "preprocessing, and modeling purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d640655-f4dc-4109-b9bb-60ae6597cb03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60ebe2a-8ab5-4267-a8d9-dcd493b8307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Perform a train-test split and divide the data into training, validation, and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ee401d0-7444-40b9-bedc-4a4becbdc69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (3918, 11) (3918,)\n",
      "Validation set shape: (490, 11) (490,)\n",
      "Test set shape: (490, 11) (490,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "wine_data = pd.read_csv(url, sep=\";\")\n",
    "\n",
    "# Separate features and target\n",
    "features = wine_data.drop(\"quality\", axis=1)  # Drop the 'quality' column\n",
    "target = wine_data[\"quality\"]\n",
    "\n",
    "# Perform train-test split\n",
    "# First, split into training and temporary set (temp_set)\n",
    "X_train, temp_set, y_train, y_temp = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Then, split the temporary set into validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(temp_set, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Display the shapes of the splits\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e57f7f-bb64-42fe-944b-ef62792ab839",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, we first perform an 80-20 train-test split, creating the X_train, y_train, \n",
    "and temp_set (temporary set) for further splitting. Then, we perform a 50-50 split on the \n",
    "temp_set to create the validation and test sets, X_val, y_val, X_test, and y_test.\n",
    "\n",
    "The test_size parameter in train_test_split defines the proportion of the dataset that\n",
    "will be used for testing. The random_state parameter ensures reproducibility by setting the random seed.\n",
    "\n",
    "Make sure to adjust the sizes and random states according to your needs and the size of your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27958574-e016-4f50-81b3-7ba87cf2aa42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32269991-41bb-4210-a0d4-ef95160f139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Perform scaling on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43307e5-afba-4d0b-bd62-b029e6e47e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaling is an important preprocessing step to ensure that features are on a similar scale,\n",
    "which can help improve the performance of various machine learning algorithms. One common \n",
    "method for scaling is standardization, which involves transforming features to have a mean\n",
    "of 0 and a standard deviation of 1.\n",
    "\n",
    "You can perform scaling using the StandardScaler from scikit-learn. Here's how you can do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2795b868-0465-4703-8ff7-38a760c52ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled training data:\n",
      "\n",
      "[[ 5.15119310e-01 -1.07623315e+00  2.27730764e-01  3.40419470e-01\n",
      "  -8.13688488e-01  5.34064605e-01 -6.41932319e-01 -4.47040725e-01\n",
      "  -3.28261014e-01 -7.02444738e-01  1.54037099e+00]\n",
      " [-6.69188091e-01 -2.88776731e-01  8.95831948e-01  1.00207124e+00\n",
      "  -2.17211567e-01  7.73947112e-01  1.35510550e+00  9.03369755e-01\n",
      "  -6.18856911e-02  2.66074147e-01 -8.21711966e-01]\n",
      " [-1.49820327e+00  4.00247639e-01 -2.28071805e-02  1.84736700e-01\n",
      "  -4.00742927e-01 -6.05377303e-01 -1.02232048e+00 -4.60280044e-01\n",
      "   4.04271124e-01  1.93263316e-03  4.81506217e-01]\n",
      " [ 4.13963498e-02 -8.79369048e-01  1.44218115e-01 -9.24503038e-01\n",
      "  -4.46625767e-01 -1.25612289e-01 -8.79674917e-01 -3.04718052e-01\n",
      "   1.37895801e-01  4.42168490e-01  2.37152807e-01]\n",
      " [ 9.88842271e-01  2.03383533e-01 -6.07395717e-01  2.43240669e+00\n",
      "   3.33382515e-01  5.42995912e-02  8.55846045e-01  1.88307932e+00\n",
      "   7.13019704e-02  8.99798045e-02 -8.86517384e-02]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "wine_data = pd.read_csv(url, sep=\";\")\n",
    "\n",
    "# Separate features and target\n",
    "features = wine_data.drop(\"quality\", axis=1)  # Drop the 'quality' column\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform training, validation, and test data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Display the first few rows of scaled training data\n",
    "print(\"Scaled training data:\\n\")\n",
    "print(X_train_scaled[:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a79d70-7761-45ac-9b23-3dbd0eb644e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, we first load the dataset and separate the features. Then,\n",
    "we initialize the StandardScaler and fit it on the training data using the fit_transform method. \n",
    "After fitting, we transform the validation and test data using the same scaler using the transform method.\n",
    "\n",
    "This ensures that the scaling parameters (mean and standard deviation) learned from the training \n",
    "data are used consistently on the validation and test data. Always keep in mind that when preprocessing\n",
    "data for your model, any transformations applied to the training data must also be applied to the validation\n",
    "and test data to ensure a fair evaluation of your model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8343b580-fb4e-4d1e-9064-1131bb7fe4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b060a883-dbd2-482b-b65e-90101bbefe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. Create at least 2 hidden layers and an output layer for the binary categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40178feb-c1a7-4aa0-b2f8-2443f2c4a9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    " To create a neural network with hidden layers and an output layer for binary categorical variables,\n",
    "    you can use libraries like TensorFlow and Keras.\n",
    "    Here's an example code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7a7d293-3ada-4b7b-9427-5773996888b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1798: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "98/98 [==============================] - 4s 16ms/step - loss: -19.6773 - accuracy: 0.0000e+00 - val_loss: -58.4375 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 1s 11ms/step - loss: -189.0838 - accuracy: 0.0000e+00 - val_loss: -397.2763 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -871.0341 - accuracy: 0.0000e+00 - val_loss: -1491.0955 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -2578.2747 - accuracy: 0.0000e+00 - val_loss: -3820.5625 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -5774.7837 - accuracy: 0.0000e+00 - val_loss: -7822.9819 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -10885.5801 - accuracy: 0.0000e+00 - val_loss: -13858.8164 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -18233.0332 - accuracy: 0.0000e+00 - val_loss: -22245.2637 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 1s 10ms/step - loss: -28135.3652 - accuracy: 0.0000e+00 - val_loss: -33231.1484 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -40919.0391 - accuracy: 0.0000e+00 - val_loss: -47133.5469 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 1s 7ms/step - loss: -56840.5781 - accuracy: 0.0000e+00 - val_loss: -64177.1211 - val_accuracy: 0.0000e+00\n",
      "31/31 [==============================] - 0s 8ms/step - loss: -66318.5938 - accuracy: 0.0000e+00\n",
      "\n",
      "Test accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "wine_data = pd.read_csv(url, sep=\";\")\n",
    "\n",
    "# Separate features and target\n",
    "features = wine_data.drop(\"quality\", axis=1)  # Drop the 'quality' column\n",
    "target = wine_data[\"quality\"]\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler and fit_transform on training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a neural network model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(X_train_scaled.shape[1],)),  # Input layer\n",
    "    keras.layers.Dense(64, activation='relu'),  # Hidden layer 1\n",
    "    keras.layers.Dense(32, activation='relu'),  # Hidden layer 2\n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"\\nTest accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f769ec8-2144-4076-9525-c8569b70970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, we're using a sequential model from Keras to create a neural network. The model consists\n",
    "of an input layer with\n",
    "the same number of input features as your dataset, two hidden layers with 64 and 32 neurons respectively,\n",
    "and an output layer with a single neuron and a sigmoid activation function, suitable for binary classification. \n",
    "We use the relu activation function for the hidden layers.\n",
    "\n",
    "The model is compiled with the Adam optimizer and binary cross-entropy loss, which is appropriate for \n",
    "binary classification problems. We then train the model using the training data and evaluate its \n",
    "performance on the test data.\n",
    "\n",
    "Feel free to adjust the number of neurons, hidden layers, and other hyperparameters to find the configuration \n",
    "that works best for your specific problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11b3eda-4c84-4904-859d-d596599dad5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d67fd4-9674-4696-9272-92652c473d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. Create a Sequential model and add all the layers to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bd2269-39d2-4eb1-9b01-7aaaa6c7d4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Here's how you can create a Sequential model in Keras and add layers to it for a multi-class classification\n",
    "problem using the Wine Quality dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5514a790-e544-472e-a983-8519c8eba8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1798: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "98/98 [==============================] - 3s 16ms/step - loss: 1.6584 - accuracy: 0.4103 - val_loss: 1.2749 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.2054 - accuracy: 0.5182 - val_loss: 1.1656 - val_accuracy: 0.5587\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 1.1206 - accuracy: 0.5440 - val_loss: 1.1337 - val_accuracy: 0.5612\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.0836 - accuracy: 0.5578 - val_loss: 1.1127 - val_accuracy: 0.5663\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 1.0596 - accuracy: 0.5581 - val_loss: 1.1023 - val_accuracy: 0.5625\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 1.0411 - accuracy: 0.5705 - val_loss: 1.0931 - val_accuracy: 0.5676\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 1.0271 - accuracy: 0.5756 - val_loss: 1.0920 - val_accuracy: 0.5702\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 1.0190 - accuracy: 0.5798 - val_loss: 1.0826 - val_accuracy: 0.5753\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 1.0063 - accuracy: 0.5826 - val_loss: 1.0769 - val_accuracy: 0.5867\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.9987 - accuracy: 0.5906 - val_loss: 1.0789 - val_accuracy: 0.5740\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.0709 - accuracy: 0.5612\n",
      "\n",
      "Test accuracy: 0.5612244606018066\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "wine_data = pd.read_csv(url, sep=\";\")\n",
    "\n",
    "# Separate features and target\n",
    "features = wine_data.drop(\"quality\", axis=1)  # Drop the 'quality' column\n",
    "target = wine_data[\"quality\"]\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler and fit_transform on training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a Sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Add layers to the model\n",
    "model.add(keras.layers.Input(shape=(X_train_scaled.shape[1],)))  # Input layer\n",
    "\n",
    "# Add hidden layers\n",
    "model.add(keras.layers.Dense(64, activation='relu'))  # Hidden layer 1\n",
    "model.add(keras.layers.Dense(32, activation='relu'))  # Hidden layer 2\n",
    "\n",
    "# Add output layer\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))  # Output layer for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"\\nTest accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39bd50a-e197-42f4-9fc8-e85b28039466",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, we're creating a Sequential model and adding layers to it using the \n",
    "model.add() method. The input layer is defined with the number of features in the dataset. \n",
    "Two hidden layers with 64 and 32 neurons and ReLU activation are added, followed by an output \n",
    "layer with 10 neurons (since we are using the Wine Quality dataset which has ratings\n",
    "                       from 1 to 10) and a softmax activation function for multi-class classification.\n",
    "\n",
    "The model is then compiled and trained on the training data. Adjust the number of neurons,\n",
    "hidden layers, activation functions, and other hyperparameters according to your needs and \n",
    "the problem you're working on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba305bcb-76a9-4255-8c08-a6ea9fe37b97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e70054-b8eb-4f34-93f1-fc7b70da97f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9. Implement a TensorBoard callback to visualize and monitor the model's training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf9fd75-5e0b-4bd0-880e-c6ff7dcaeec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TensorBoard is a great tool for visualizing and monitoring the training process of your neural \n",
    "network models. Here's how you can implement\n",
    "a TensorBoard callback in your Keras code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b84fd674-e78b-45dc-998f-425d6c71704e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1798: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 3s 17ms/step - loss: 1.5858 - accuracy: 0.4056 - val_loss: 1.2472 - val_accuracy: 0.5179\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 1.2132 - accuracy: 0.5252 - val_loss: 1.1798 - val_accuracy: 0.5446\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 1.1464 - accuracy: 0.5440 - val_loss: 1.1459 - val_accuracy: 0.5536\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 1s 11ms/step - loss: 1.1034 - accuracy: 0.5514 - val_loss: 1.1252 - val_accuracy: 0.5599\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 1.0760 - accuracy: 0.5558 - val_loss: 1.1148 - val_accuracy: 0.5714\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 1s 12ms/step - loss: 1.0559 - accuracy: 0.5660 - val_loss: 1.1057 - val_accuracy: 0.5740\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.0422 - accuracy: 0.5718 - val_loss: 1.1013 - val_accuracy: 0.5599\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.0279 - accuracy: 0.5750 - val_loss: 1.0993 - val_accuracy: 0.5765\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.0176 - accuracy: 0.5766 - val_loss: 1.1057 - val_accuracy: 0.5651\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 1.0133 - accuracy: 0.5801 - val_loss: 1.0860 - val_accuracy: 0.5765\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 1.0857 - accuracy: 0.5459\n",
      "\n",
      "Test accuracy: 0.545918345451355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "wine_data = pd.read_csv(url, sep=\";\")\n",
    "\n",
    "# Separate features and target\n",
    "features = wine_data.drop(\"quality\", axis=1)  # Drop the 'quality' column\n",
    "target = wine_data[\"quality\"]\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler and fit_transform on training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a Sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Add layers to the model\n",
    "model.add(keras.layers.Input(shape=(X_train_scaled.shape[1],)))  # Input layer\n",
    "model.add(keras.layers.Dense(64, activation='relu'))  # Hidden layer 1\n",
    "model.add(keras.layers.Dense(32, activation='relu'))  # Hidden layer 2\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))  # Output layer for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create a TensorBoard callback\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=\"./logs\", histogram_freq=1)\n",
    "\n",
    "# Train the model with the TensorBoard callback\n",
    "history = model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[tensorboard_callback])\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"\\nTest accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b27b186-c645-480c-90f3-470cf749a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, we've added a TensorBoard callback to the model.fit() call by passing it as a list\n",
    "in the callbacks parameter. The log_dir argument specifies where the TensorBoard logs will be stored.\n",
    "You can adjust the directory path as needed.\n",
    "\n",
    "After training, you can launch TensorBoard from the terminal using the following command:\n",
    "\n",
    "\n",
    "tensorboard --logdir=./logs\n",
    "This will start TensorBoard, and you can access it by opening a web browser and navigating to\n",
    "the URL provided in the terminal (usually http://localhost:6006/). TensorBoard will allow you \n",
    "to visualize various aspects of your model's training, such as loss curves, metrics, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50f8569-be54-4101-a6c4-8d77ade6e72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286b8d9f-7536-439d-9e99-4522fa681684",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q10. Use Early Stopping to prevent overfitting by monitoring a chosen metric and stopping the training if \n",
    "no improvement is observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e3b60b-0dd0-4d10-bedf-e4a0f2edfc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "Early Stopping is a technique used to prevent overfitting by monitoring a\n",
    "chosen metric (such as validation loss or accuracy) during the training process.\n",
    "If the chosen metric stops improving for a certain number of epochs, the training is\n",
    "stopped early to avoid overfitting. Here's how you can implement Early Stopping in your Keras code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e32bb16-d500-4249-97e2-3eef0f933c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1798: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 3s 15ms/step - loss: 1.5402 - accuracy: 0.4362 - val_loss: 1.2226 - val_accuracy: 0.5191\n",
      "Epoch 2/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 1.1776 - accuracy: 0.5306 - val_loss: 1.1467 - val_accuracy: 0.5765\n",
      "Epoch 3/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.1163 - accuracy: 0.5453 - val_loss: 1.1200 - val_accuracy: 0.5651\n",
      "Epoch 4/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 1.0799 - accuracy: 0.5574 - val_loss: 1.1070 - val_accuracy: 0.5702\n",
      "Epoch 5/100\n",
      "98/98 [==============================] - 1s 11ms/step - loss: 1.0640 - accuracy: 0.5645 - val_loss: 1.1024 - val_accuracy: 0.5612\n",
      "Epoch 6/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.0464 - accuracy: 0.5692 - val_loss: 1.0915 - val_accuracy: 0.5676\n",
      "Epoch 7/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 1.0351 - accuracy: 0.5759 - val_loss: 1.0861 - val_accuracy: 0.5561\n",
      "Epoch 8/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 1.0256 - accuracy: 0.5680 - val_loss: 1.0837 - val_accuracy: 0.5689\n",
      "Epoch 9/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 1.0139 - accuracy: 0.5753 - val_loss: 1.0790 - val_accuracy: 0.5561\n",
      "Epoch 10/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 1.0057 - accuracy: 0.5833 - val_loss: 1.0730 - val_accuracy: 0.5663\n",
      "Epoch 11/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.9990 - accuracy: 0.5836 - val_loss: 1.0689 - val_accuracy: 0.5612\n",
      "Epoch 12/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.9891 - accuracy: 0.5842 - val_loss: 1.0673 - val_accuracy: 0.5599\n",
      "Epoch 13/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.9812 - accuracy: 0.5913 - val_loss: 1.0639 - val_accuracy: 0.5625\n",
      "Epoch 14/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.9765 - accuracy: 0.5913 - val_loss: 1.0678 - val_accuracy: 0.5676\n",
      "Epoch 15/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.9694 - accuracy: 0.5903 - val_loss: 1.0597 - val_accuracy: 0.5651\n",
      "Epoch 16/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.9644 - accuracy: 0.5842 - val_loss: 1.0532 - val_accuracy: 0.5778\n",
      "Epoch 17/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.9554 - accuracy: 0.5906 - val_loss: 1.0498 - val_accuracy: 0.5791\n",
      "Epoch 18/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.9563 - accuracy: 0.5938 - val_loss: 1.0524 - val_accuracy: 0.5625\n",
      "Epoch 19/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.9440 - accuracy: 0.5960 - val_loss: 1.0569 - val_accuracy: 0.5702\n",
      "Epoch 20/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.9437 - accuracy: 0.5929 - val_loss: 1.0516 - val_accuracy: 0.5702\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 1.0663 - accuracy: 0.5510\n",
      "\n",
      "Test accuracy: 0.5510203838348389\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "wine_data = pd.read_csv(url, sep=\";\")\n",
    "\n",
    "# Separate features and target\n",
    "features = wine_data.drop(\"quality\", axis=1)  # Drop the 'quality' column\n",
    "target = wine_data[\"quality\"]\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler and fit_transform on training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a Sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Add layers to the model\n",
    "model.add(keras.layers.Input(shape=(X_train_scaled.shape[1],)))  # Input layer\n",
    "model.add(keras.layers.Dense(64, activation='relu'))  # Hidden layer 1\n",
    "model.add(keras.layers.Dense(32, activation='relu'))  # Hidden layer 2\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))  # Output layer for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create an EarlyStopping callback\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train the model with the EarlyStopping callback\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping_callback])\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"\\nTest accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e7583a-bd3a-4a87-917a-f05c1e8da98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, we've added an EarlyStopping callback to the model.fit() call by passing it\n",
    "as a list in the callbacks parameter. The monitor parameter specifies the metric to monitor\n",
    "for improvement (in this case, validation loss). The patience parameter determines how many\n",
    "epochs with no improvement are tolerated before training is stopped. The restore_best_weights\n",
    "parameter ensures that the model's weights are restored to the best values when training is stopped.\n",
    "\n",
    "By using the EarlyStopping callback, you can prevent overfitting by stopping the training \n",
    "process as soon as the validation loss starts to deteriorate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c024c8-da5d-4656-8c67-7b6987b90997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2fc258-d488-4555-8657-311eb5623f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q11. Implement a ModelCheckpoint callback to save the best model based on a chosen metric during \n",
    "training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06a9b7f-e2c4-473a-9051-22b196f738f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "The ModelCheckpoint callback in Keras allows you to save the best model based on a chosen metric during training.\n",
    "This is particularly useful to ensure that you have the best model saved even if training is stopped early due\n",
    "to Early Stopping or other reasons. \n",
    "Here's how you can implement the ModelCheckpoint callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e26df97a-ab7a-4e13-a698-47db4eb228c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1798: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "98/98 [==============================] - 3s 14ms/step - loss: 1.5723 - accuracy: 0.4627 - val_loss: 1.2453 - val_accuracy: 0.5485\n",
      "Epoch 2/100\n",
      "32/98 [========>.....................] - ETA: 0s - loss: 1.2380 - accuracy: 0.5205"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 1s 8ms/step - loss: 1.1794 - accuracy: 0.5434 - val_loss: 1.1436 - val_accuracy: 0.5651\n",
      "Epoch 3/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 1.1062 - accuracy: 0.5530 - val_loss: 1.1168 - val_accuracy: 0.5548\n",
      "Epoch 4/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.0743 - accuracy: 0.5587 - val_loss: 1.1056 - val_accuracy: 0.5536\n",
      "Epoch 5/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 1.0558 - accuracy: 0.5578 - val_loss: 1.0925 - val_accuracy: 0.5638\n",
      "Epoch 6/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.0432 - accuracy: 0.5641 - val_loss: 1.0798 - val_accuracy: 0.5778\n",
      "Epoch 7/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 1.0312 - accuracy: 0.5689 - val_loss: 1.0744 - val_accuracy: 0.5651\n",
      "Epoch 8/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 1.0199 - accuracy: 0.5750 - val_loss: 1.0782 - val_accuracy: 0.5638\n",
      "Epoch 9/100\n",
      "98/98 [==============================] - 1s 11ms/step - loss: 1.0134 - accuracy: 0.5763 - val_loss: 1.0680 - val_accuracy: 0.5842\n",
      "Epoch 10/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 1.0046 - accuracy: 0.5772 - val_loss: 1.0629 - val_accuracy: 0.5765\n",
      "Epoch 11/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 1.0004 - accuracy: 0.5807 - val_loss: 1.0578 - val_accuracy: 0.5753\n",
      "Epoch 12/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.9898 - accuracy: 0.5881 - val_loss: 1.0622 - val_accuracy: 0.5829\n",
      "Epoch 13/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.9853 - accuracy: 0.5852 - val_loss: 1.0550 - val_accuracy: 0.5893\n",
      "Epoch 14/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.9771 - accuracy: 0.5849 - val_loss: 1.0545 - val_accuracy: 0.5842\n",
      "Epoch 15/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.9680 - accuracy: 0.5922 - val_loss: 1.0471 - val_accuracy: 0.5867\n",
      "Epoch 16/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.9650 - accuracy: 0.5862 - val_loss: 1.0573 - val_accuracy: 0.5702\n",
      "Epoch 17/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.9607 - accuracy: 0.5938 - val_loss: 1.0401 - val_accuracy: 0.5816\n",
      "Epoch 18/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.9544 - accuracy: 0.5916 - val_loss: 1.0484 - val_accuracy: 0.5842\n",
      "Epoch 19/100\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 0.9478 - accuracy: 0.6005 - val_loss: 1.0350 - val_accuracy: 0.5918\n",
      "Epoch 20/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.9413 - accuracy: 0.5954 - val_loss: 1.0434 - val_accuracy: 0.5804\n",
      "Epoch 21/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.9371 - accuracy: 0.5989 - val_loss: 1.0358 - val_accuracy: 0.5676\n",
      "Epoch 22/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.9346 - accuracy: 0.5964 - val_loss: 1.0427 - val_accuracy: 0.5599\n",
      "Epoch 23/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.9283 - accuracy: 0.6053 - val_loss: 1.0372 - val_accuracy: 0.5804\n",
      "Epoch 24/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.9211 - accuracy: 0.6024 - val_loss: 1.0351 - val_accuracy: 0.5765\n",
      "Epoch 25/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.9170 - accuracy: 0.6120 - val_loss: 1.0313 - val_accuracy: 0.5855\n",
      "Epoch 26/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.9168 - accuracy: 0.6059 - val_loss: 1.0361 - val_accuracy: 0.5906\n",
      "Epoch 27/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.9112 - accuracy: 0.6059 - val_loss: 1.0339 - val_accuracy: 0.5791\n",
      "Epoch 28/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.9087 - accuracy: 0.6037 - val_loss: 1.0356 - val_accuracy: 0.5816\n",
      "Epoch 29/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.9041 - accuracy: 0.6130 - val_loss: 1.0329 - val_accuracy: 0.5689\n",
      "Epoch 30/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.8983 - accuracy: 0.6177 - val_loss: 1.0404 - val_accuracy: 0.5651\n",
      "Epoch 31/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.8948 - accuracy: 0.6123 - val_loss: 1.0334 - val_accuracy: 0.5740\n",
      "Epoch 32/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.8904 - accuracy: 0.6187 - val_loss: 1.0401 - val_accuracy: 0.5791\n",
      "Epoch 33/100\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 0.8869 - accuracy: 0.6209 - val_loss: 1.0323 - val_accuracy: 0.5778\n",
      "Epoch 34/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.8809 - accuracy: 0.6270 - val_loss: 1.0351 - val_accuracy: 0.5689\n",
      "Epoch 35/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.8799 - accuracy: 0.6238 - val_loss: 1.0355 - val_accuracy: 0.5727\n",
      "Epoch 36/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.8788 - accuracy: 0.6228 - val_loss: 1.0331 - val_accuracy: 0.5651\n",
      "Epoch 37/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 0.8712 - accuracy: 0.6168 - val_loss: 1.0355 - val_accuracy: 0.5740\n",
      "Epoch 38/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.8686 - accuracy: 0.6267 - val_loss: 1.0345 - val_accuracy: 0.5510\n",
      "Epoch 39/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.8668 - accuracy: 0.6228 - val_loss: 1.0316 - val_accuracy: 0.5765\n",
      "Epoch 40/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.8620 - accuracy: 0.6299 - val_loss: 1.0369 - val_accuracy: 0.5651\n",
      "Epoch 41/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.8582 - accuracy: 0.6327 - val_loss: 1.0547 - val_accuracy: 0.5689\n",
      "Epoch 42/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.8550 - accuracy: 0.6273 - val_loss: 1.0385 - val_accuracy: 0.5791\n",
      "Epoch 43/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.8510 - accuracy: 0.6382 - val_loss: 1.0417 - val_accuracy: 0.5702\n",
      "Epoch 44/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.8485 - accuracy: 0.6331 - val_loss: 1.0417 - val_accuracy: 0.5804\n",
      "Epoch 45/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.8447 - accuracy: 0.6449 - val_loss: 1.0394 - val_accuracy: 0.5753\n",
      "Epoch 46/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.8449 - accuracy: 0.6398 - val_loss: 1.0423 - val_accuracy: 0.5663\n",
      "Epoch 47/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.8414 - accuracy: 0.6461 - val_loss: 1.0408 - val_accuracy: 0.5612\n",
      "Epoch 48/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.8333 - accuracy: 0.6433 - val_loss: 1.0485 - val_accuracy: 0.5727\n",
      "Epoch 49/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.8301 - accuracy: 0.6449 - val_loss: 1.0693 - val_accuracy: 0.5548\n",
      "Epoch 50/100\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 0.8314 - accuracy: 0.6481 - val_loss: 1.0398 - val_accuracy: 0.5676\n",
      "Epoch 51/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.8249 - accuracy: 0.6506 - val_loss: 1.0553 - val_accuracy: 0.5612\n",
      "Epoch 52/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.8243 - accuracy: 0.6433 - val_loss: 1.0481 - val_accuracy: 0.5587\n",
      "Epoch 53/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.8216 - accuracy: 0.6490 - val_loss: 1.0452 - val_accuracy: 0.5638\n",
      "Epoch 54/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.8139 - accuracy: 0.6496 - val_loss: 1.0498 - val_accuracy: 0.5651\n",
      "Epoch 55/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.8158 - accuracy: 0.6541 - val_loss: 1.0550 - val_accuracy: 0.5510\n",
      "Epoch 56/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.8085 - accuracy: 0.6627 - val_loss: 1.0571 - val_accuracy: 0.5702\n",
      "Epoch 57/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.8066 - accuracy: 0.6573 - val_loss: 1.0564 - val_accuracy: 0.5599\n",
      "Epoch 58/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.8043 - accuracy: 0.6615 - val_loss: 1.0577 - val_accuracy: 0.5702\n",
      "Epoch 59/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.8030 - accuracy: 0.6557 - val_loss: 1.0507 - val_accuracy: 0.5740\n",
      "Epoch 60/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.7991 - accuracy: 0.6583 - val_loss: 1.0595 - val_accuracy: 0.5689\n",
      "Epoch 61/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.7988 - accuracy: 0.6605 - val_loss: 1.0665 - val_accuracy: 0.5548\n",
      "Epoch 62/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.7926 - accuracy: 0.6608 - val_loss: 1.0776 - val_accuracy: 0.5561\n",
      "Epoch 63/100\n",
      "98/98 [==============================] - 1s 11ms/step - loss: 0.7923 - accuracy: 0.6678 - val_loss: 1.0725 - val_accuracy: 0.5714\n",
      "Epoch 64/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.7930 - accuracy: 0.6631 - val_loss: 1.0647 - val_accuracy: 0.5702\n",
      "Epoch 65/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.7846 - accuracy: 0.6726 - val_loss: 1.0730 - val_accuracy: 0.5599\n",
      "Epoch 66/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.7808 - accuracy: 0.6675 - val_loss: 1.0699 - val_accuracy: 0.5663\n",
      "Epoch 67/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.7821 - accuracy: 0.6704 - val_loss: 1.0778 - val_accuracy: 0.5663\n",
      "Epoch 68/100\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 0.7804 - accuracy: 0.6733 - val_loss: 1.0725 - val_accuracy: 0.5765\n",
      "Epoch 69/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.7759 - accuracy: 0.6704 - val_loss: 1.0654 - val_accuracy: 0.5523\n",
      "Epoch 70/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.7760 - accuracy: 0.6710 - val_loss: 1.0826 - val_accuracy: 0.5574\n",
      "Epoch 71/100\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.7662 - accuracy: 0.6765 - val_loss: 1.0700 - val_accuracy: 0.5561\n",
      "Epoch 72/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.7691 - accuracy: 0.6742 - val_loss: 1.0870 - val_accuracy: 0.5472\n",
      "Epoch 73/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.7668 - accuracy: 0.6806 - val_loss: 1.0767 - val_accuracy: 0.5816\n",
      "Epoch 74/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.7590 - accuracy: 0.6758 - val_loss: 1.0754 - val_accuracy: 0.5625\n",
      "Epoch 75/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.7577 - accuracy: 0.6822 - val_loss: 1.0760 - val_accuracy: 0.5702\n",
      "Epoch 76/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.7599 - accuracy: 0.6838 - val_loss: 1.0939 - val_accuracy: 0.5574\n",
      "Epoch 77/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.7530 - accuracy: 0.6857 - val_loss: 1.0785 - val_accuracy: 0.5663\n",
      "Epoch 78/100\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 0.7506 - accuracy: 0.6841 - val_loss: 1.0810 - val_accuracy: 0.5740\n",
      "Epoch 79/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.7487 - accuracy: 0.6825 - val_loss: 1.0895 - val_accuracy: 0.5791\n",
      "Epoch 80/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.7474 - accuracy: 0.6870 - val_loss: 1.0915 - val_accuracy: 0.5714\n",
      "Epoch 81/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.7500 - accuracy: 0.6828 - val_loss: 1.0872 - val_accuracy: 0.5714\n",
      "Epoch 82/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.7419 - accuracy: 0.6927 - val_loss: 1.0882 - val_accuracy: 0.5816\n",
      "Epoch 83/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.7411 - accuracy: 0.6847 - val_loss: 1.0939 - val_accuracy: 0.5816\n",
      "Epoch 84/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.7367 - accuracy: 0.6899 - val_loss: 1.0923 - val_accuracy: 0.5791\n",
      "Epoch 85/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.7390 - accuracy: 0.6908 - val_loss: 1.0941 - val_accuracy: 0.5829\n",
      "Epoch 86/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.7309 - accuracy: 0.6946 - val_loss: 1.0940 - val_accuracy: 0.5702\n",
      "Epoch 87/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.7315 - accuracy: 0.6930 - val_loss: 1.1033 - val_accuracy: 0.5651\n",
      "Epoch 88/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.7256 - accuracy: 0.6985 - val_loss: 1.0959 - val_accuracy: 0.5765\n",
      "Epoch 89/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.7223 - accuracy: 0.6981 - val_loss: 1.0962 - val_accuracy: 0.5651\n",
      "Epoch 90/100\n",
      "98/98 [==============================] - 1s 11ms/step - loss: 0.7223 - accuracy: 0.7029 - val_loss: 1.1111 - val_accuracy: 0.5599\n",
      "Epoch 91/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.7226 - accuracy: 0.7004 - val_loss: 1.1074 - val_accuracy: 0.5816\n",
      "Epoch 92/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.7173 - accuracy: 0.6978 - val_loss: 1.0993 - val_accuracy: 0.5727\n",
      "Epoch 93/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.7153 - accuracy: 0.7052 - val_loss: 1.1088 - val_accuracy: 0.5587\n",
      "Epoch 94/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.7152 - accuracy: 0.7049 - val_loss: 1.1048 - val_accuracy: 0.5702\n",
      "Epoch 95/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.7097 - accuracy: 0.7068 - val_loss: 1.1084 - val_accuracy: 0.5702\n",
      "Epoch 96/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.7083 - accuracy: 0.7084 - val_loss: 1.1141 - val_accuracy: 0.5765\n",
      "Epoch 97/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.7060 - accuracy: 0.7122 - val_loss: 1.1216 - val_accuracy: 0.5765\n",
      "Epoch 98/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.7060 - accuracy: 0.7055 - val_loss: 1.1146 - val_accuracy: 0.5893\n",
      "Epoch 99/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.7041 - accuracy: 0.7042 - val_loss: 1.1257 - val_accuracy: 0.5689\n",
      "Epoch 100/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.6991 - accuracy: 0.7125 - val_loss: 1.1213 - val_accuracy: 0.5778\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.0368 - accuracy: 0.5622\n",
      "\n",
      "Test accuracy of the best model: 0.5622448921203613\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "wine_data = pd.read_csv(url, sep=\";\")\n",
    "\n",
    "# Separate features and target\n",
    "features = wine_data.drop(\"quality\", axis=1)  # Drop the 'quality' column\n",
    "target = wine_data[\"quality\"]\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler and fit_transform on training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a Sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Add layers to the model\n",
    "model.add(keras.layers.Input(shape=(X_train_scaled.shape[1],)))  # Input layer\n",
    "model.add(keras.layers.Dense(64, activation='relu'))  # Hidden layer 1\n",
    "model.add(keras.layers.Dense(32, activation='relu'))  # Hidden layer 2\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))  # Output layer for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create a ModelCheckpoint callback\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True)\n",
    "\n",
    "# Train the model with the ModelCheckpoint callback\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[model_checkpoint_callback])\n",
    "\n",
    "# Load the best saved model\n",
    "best_model = keras.models.load_model('best_model.h5')\n",
    "\n",
    "# Evaluate the best model on test data\n",
    "test_loss, test_accuracy = best_model.evaluate(X_test_scaled, y_test)\n",
    "print(\"\\nTest accuracy of the best model:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9407d3d0-3213-42f1-9506-aa0e46b6fbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, the ModelCheckpoint callback is created and added to the model.\n",
    "fit() call using the callbacks parameter. The monitor parameter specifies the metric\n",
    "to monitor for improvement (in this case, validation accuracy). The save_best_only parameter \n",
    "ensures that only the best model (based on the monitored metric) is saved.\n",
    "\n",
    "After training, you can load the best saved model using keras.models.load_model() and evaluate\n",
    "its performance on the test data. This ensures that you're using the best model obtained during \n",
    "training for your final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeed944-ee85-4ade-b665-351c88a3086a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b188f3-9d0f-4f8c-9598-21d240413167",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q12. Print the model summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4585ff56-f310-4b7c-a5d0-b3e8ffadd5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    " We can use the summary() method of your Keras model to print a summary of the \n",
    "    model's architecture and parameters. Here's how you can do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e86fea69-a76e-4f33-86c1-7baf8403d944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 64)                768       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3178 (12.41 KB)\n",
      "Trainable params: 3178 (12.41 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "wine_data = pd.read_csv(url, sep=\";\")\n",
    "\n",
    "# Separate features and target\n",
    "features = wine_data.drop(\"quality\", axis=1)  # Drop the 'quality' column\n",
    "target = wine_data[\"quality\"]\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler and fit_transform on training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a Sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Add layers to the model\n",
    "model.add(keras.layers.Input(shape=(X_train_scaled.shape[1],)))  # Input layer\n",
    "model.add(keras.layers.Dense(64, activation='relu'))  # Hidden layer 1\n",
    "model.add(keras.layers.Dense(32, activation='relu'))  # Hidden layer 2\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))  # Output layer for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bb5eb6-bd5d-42a5-bd15-6e11f84a1e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, the model.summary() method is called after creating the model and compiling it. \n",
    "This will print a summary of the model's architecture, including the layers, their output shapes, \n",
    "and the number of parameters in each layer.\n",
    "\n",
    "The model summary is a useful tool to quickly understand the structure of your neural network and\n",
    "ensure that it's constructed as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c358c32-65be-4a2d-8e42-4ebf1f772f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c4bb10-f69a-42e5-97f1-7d697e3b9557",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q13. Use binary cross-entropy as the loss function, Adam optimizer, and include the metric ['accuracy']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013be0be-e38f-4536-b7f8-25e217a865c7",
   "metadata": {},
   "outputs": [],
   "source": [
    " Here's how you can configure your Keras model with binary cross-entropy as the loss function, \n",
    "    the Adam optimizer, and include the accuracy metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bed51a5-d86e-4d43-b4aa-d0a28554bd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 64)                768       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2881 (11.25 KB)\n",
      "Trainable params: 2881 (11.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "wine_data = pd.read_csv(url, sep=\";\")\n",
    "\n",
    "# Separate features and target\n",
    "features = wine_data.drop(\"quality\", axis=1)  # Drop the 'quality' column\n",
    "target = wine_data[\"quality\"]\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler and fit_transform on training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a Sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Add layers to the model\n",
    "model.add(keras.layers.Input(shape=(X_train_scaled.shape[1],)))  # Input layer\n",
    "model.add(keras.layers.Dense(64, activation='relu'))  # Hidden layer 1\n",
    "model.add(keras.layers.Dense(32, activation='relu'))  # Hidden layer 2\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c462a5d-dc94-4aa9-9b3a-058f99fc23f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, we've made the following changes:\n",
    "\n",
    "Changed the activation function of the output layer to 'sigmoid', which is suitable for binary classification.\n",
    "Changed the loss function to 'binary_crossentropy', which is appropriate for binary classification problems.\n",
    "Added the 'accuracy' metric to the metrics list when compiling the model.\n",
    "These changes ensure that your model is configured correctly for binary classification, \n",
    "using binary cross-entropy as the loss function and monitoring the accuracy metric during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2719165d-9912-4c18-b478-5e1343335a83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46c2736-6370-484b-bdfe-3bb839310cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q14. Compile the model with the specified loss function, optimizer, and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760e742b-2298-4d15-ab3f-ab0095145fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Here's the code to compile the model with the specified loss function, optimizer, and metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fd1aee0-a406-409c-af29-8854bdb65bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            (None, 64)                768       \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2881 (11.25 KB)\n",
      "Trainable params: 2881 (11.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "wine_data = pd.read_csv(url, sep=\";\")\n",
    "\n",
    "# Separate features and target\n",
    "features = wine_data.drop(\"quality\", axis=1)  # Drop the 'quality' column\n",
    "target = wine_data[\"quality\"]\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler and fit_transform on training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a Sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Add layers to the model\n",
    "model.add(keras.layers.Input(shape=(X_train_scaled.shape[1],)))  # Input layer\n",
    "model.add(keras.layers.Dense(64, activation='relu'))  # Hidden layer 1\n",
    "model.add(keras.layers.Dense(32, activation='relu'))  # Hidden layer 2\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model with specified loss function, optimizer, and metrics\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc66986a-f482-4b8e-8031-8e9321d173e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, the model has been compiled using the 'adam' optimizer, 'binary_crossentropy' \n",
    "loss function (appropriate for binary classification), and the 'accuracy' metric.\n",
    "This configuration ensures that the model is trained using the specified settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d35aec9-84dc-47ab-8380-5b1a6c95af91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae66829-3d4b-4a34-8164-9180ec37d25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q15. Fit the model to the data, incorporating the TensorBoard, Early Stopping, and ModelCheckpoint \n",
    "callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb0eca2-3dee-43ba-bfb4-2b4aa44029af",
   "metadata": {},
   "outputs": [],
   "source": [
    "Here's how you can fit the compiled model to the data while incorporating the TensorBoard,\n",
    "Early Stopping, and ModelCheckpoint callbacks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6e1c1f4-0d31-42bc-a625-b013789a4fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1798: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "98/98 [==============================] - 3s 16ms/step - loss: -32.8047 - accuracy: 0.0000e+00 - val_loss: -98.2109 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "35/98 [=========>....................] - ETA: 0s - loss: -155.2538 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 1s 11ms/step - loss: -313.0027 - accuracy: 0.0000e+00 - val_loss: -650.2691 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -1359.3174 - accuracy: 0.0000e+00 - val_loss: -2270.1807 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "98/98 [==============================] - 1s 10ms/step - loss: -3805.7410 - accuracy: 0.0000e+00 - val_loss: -5556.4814 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -8254.6143 - accuracy: 0.0000e+00 - val_loss: -11093.3955 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -15268.8809 - accuracy: 0.0000e+00 - val_loss: -19363.1973 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -25317.8457 - accuracy: 0.0000e+00 - val_loss: -30874.7441 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "98/98 [==============================] - 1s 11ms/step - loss: -38856.0508 - accuracy: 0.0000e+00 - val_loss: -45909.3359 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -56255.3516 - accuracy: 0.0000e+00 - val_loss: -64992.7383 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -77847.3281 - accuracy: 0.0000e+00 - val_loss: -88267.9375 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -103986.0625 - accuracy: 0.0000e+00 - val_loss: -116069.6016 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -134901.3906 - accuracy: 0.0000e+00 - val_loss: -148914.6562 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: -170952.8906 - accuracy: 0.0000e+00 - val_loss: -186543.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -212324.2812 - accuracy: 0.0000e+00 - val_loss: -229579.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "98/98 [==============================] - 1s 12ms/step - loss: -259144.4688 - accuracy: 0.0000e+00 - val_loss: -278042.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: -311593.5312 - accuracy: 0.0000e+00 - val_loss: -332063.1250 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -369945.7812 - accuracy: 0.0000e+00 - val_loss: -392026.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "98/98 [==============================] - 1s 10ms/step - loss: -434308.4062 - accuracy: 0.0000e+00 - val_loss: -457939.1562 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -504907.8438 - accuracy: 0.0000e+00 - val_loss: -529641.3125 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -581760.1875 - accuracy: 0.0000e+00 - val_loss: -607918.3125 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -665144.7500 - accuracy: 0.0000e+00 - val_loss: -692574.6875 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -755071.5625 - accuracy: 0.0000e+00 - val_loss: -783697.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: -851727.6875 - accuracy: 0.0000e+00 - val_loss: -881422.6875 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -955216.3750 - accuracy: 0.0000e+00 - val_loss: -985526.6875 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -1065451.0000 - accuracy: 0.0000e+00 - val_loss: -1096776.3750 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -1182714.5000 - accuracy: 0.0000e+00 - val_loss: -1214408.3750 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -1307159.2500 - accuracy: 0.0000e+00 - val_loss: -1339244.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -1438830.8750 - accuracy: 0.0000e+00 - val_loss: -1470961.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -1577766.8750 - accuracy: 0.0000e+00 - val_loss: -1609754.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -1723729.6250 - accuracy: 0.0000e+00 - val_loss: -1756502.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -1877202.6250 - accuracy: 0.0000e+00 - val_loss: -1909570.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: -2038025.0000 - accuracy: 0.0000e+00 - val_loss: -2070136.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -2206384.2500 - accuracy: 0.0000e+00 - val_loss: -2238282.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: -2382552.2500 - accuracy: 0.0000e+00 - val_loss: -2412899.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: -2566181.0000 - accuracy: 0.0000e+00 - val_loss: -2596691.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -2757899.5000 - accuracy: 0.0000e+00 - val_loss: -2786824.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -2957135.5000 - accuracy: 0.0000e+00 - val_loss: -2985634.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -3164471.5000 - accuracy: 0.0000e+00 - val_loss: -3191528.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: -3379640.5000 - accuracy: 0.0000e+00 - val_loss: -3405524.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -3603038.7500 - accuracy: 0.0000e+00 - val_loss: -3626803.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: -3834598.7500 - accuracy: 0.0000e+00 - val_loss: -3856232.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -4074433.5000 - accuracy: 0.0000e+00 - val_loss: -4093582.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -4322616.5000 - accuracy: 0.0000e+00 - val_loss: -4340313.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -4579244.5000 - accuracy: 0.0000e+00 - val_loss: -4594960.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -4844305.5000 - accuracy: 0.0000e+00 - val_loss: -4857239.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "98/98 [==============================] - 1s 10ms/step - loss: -5118037.5000 - accuracy: 0.0000e+00 - val_loss: -5129004.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "98/98 [==============================] - 1s 10ms/step - loss: -5400765.0000 - accuracy: 0.0000e+00 - val_loss: -5407803.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -5691986.5000 - accuracy: 0.0000e+00 - val_loss: -5696004.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "98/98 [==============================] - 1s 12ms/step - loss: -5992123.0000 - accuracy: 0.0000e+00 - val_loss: -5993477.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -6301198.5000 - accuracy: 0.0000e+00 - val_loss: -6298680.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -6619151.5000 - accuracy: 0.0000e+00 - val_loss: -6612872.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -6946245.0000 - accuracy: 0.0000e+00 - val_loss: -6936672.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "98/98 [==============================] - 1s 11ms/step - loss: -7282453.5000 - accuracy: 0.0000e+00 - val_loss: -7268426.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "98/98 [==============================] - 1s 10ms/step - loss: -7627575.5000 - accuracy: 0.0000e+00 - val_loss: -7609312.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -7982142.0000 - accuracy: 0.0000e+00 - val_loss: -7959735.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -8346218.0000 - accuracy: 0.0000e+00 - val_loss: -8319212.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -8719669.0000 - accuracy: 0.0000e+00 - val_loss: -8687104.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "98/98 [==============================] - 1s 10ms/step - loss: -9102703.0000 - accuracy: 0.0000e+00 - val_loss: -9064813.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: -9495278.0000 - accuracy: 0.0000e+00 - val_loss: -9453228.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -9898066.0000 - accuracy: 0.0000e+00 - val_loss: -9850015.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -10310259.0000 - accuracy: 0.0000e+00 - val_loss: -10257068.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -10732619.0000 - accuracy: 0.0000e+00 - val_loss: -10674425.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -11164954.0000 - accuracy: 0.0000e+00 - val_loss: -11099238.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -11606799.0000 - accuracy: 0.0000e+00 - val_loss: -11535731.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: -12059057.0000 - accuracy: 0.0000e+00 - val_loss: -11981520.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -12521476.0000 - accuracy: 0.0000e+00 - val_loss: -12436483.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -12994112.0000 - accuracy: 0.0000e+00 - val_loss: -12901784.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: -13477285.0000 - accuracy: 0.0000e+00 - val_loss: -13377294.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: -13970955.0000 - accuracy: 0.0000e+00 - val_loss: -13863087.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: -14475199.0000 - accuracy: 0.0000e+00 - val_loss: -14360094.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -14990033.0000 - accuracy: 0.0000e+00 - val_loss: -14867800.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -15515747.0000 - accuracy: 0.0000e+00 - val_loss: -15385149.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: -16052238.0000 - accuracy: 0.0000e+00 - val_loss: -15912967.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -16599850.0000 - accuracy: 0.0000e+00 - val_loss: -16450936.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -17158082.0000 - accuracy: 0.0000e+00 - val_loss: -17002758.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -17728200.0000 - accuracy: 0.0000e+00 - val_loss: -17561710.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -18308986.0000 - accuracy: 0.0000e+00 - val_loss: -18132372.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -18900790.0000 - accuracy: 0.0000e+00 - val_loss: -18716482.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -19503846.0000 - accuracy: 0.0000e+00 - val_loss: -19309636.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -20118526.0000 - accuracy: 0.0000e+00 - val_loss: -19912596.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -20744374.0000 - accuracy: 0.0000e+00 - val_loss: -20529858.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -21381828.0000 - accuracy: 0.0000e+00 - val_loss: -21156856.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: -22031250.0000 - accuracy: 0.0000e+00 - val_loss: -21792992.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "98/98 [==============================] - 1s 11ms/step - loss: -22691522.0000 - accuracy: 0.0000e+00 - val_loss: -22442792.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -23364334.0000 - accuracy: 0.0000e+00 - val_loss: -23102862.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -24048680.0000 - accuracy: 0.0000e+00 - val_loss: -23777018.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -24744882.0000 - accuracy: 0.0000e+00 - val_loss: -24463804.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -25453668.0000 - accuracy: 0.0000e+00 - val_loss: -25157096.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -26174128.0000 - accuracy: 0.0000e+00 - val_loss: -25861888.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -26905434.0000 - accuracy: 0.0000e+00 - val_loss: -26586900.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -27651162.0000 - accuracy: 0.0000e+00 - val_loss: -27315568.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -28408194.0000 - accuracy: 0.0000e+00 - val_loss: -28060510.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -29178292.0000 - accuracy: 0.0000e+00 - val_loss: -28817744.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -29961244.0000 - accuracy: 0.0000e+00 - val_loss: -29585162.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: -30756036.0000 - accuracy: 0.0000e+00 - val_loss: -30369192.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -31564928.0000 - accuracy: 0.0000e+00 - val_loss: -31159954.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -32385690.0000 - accuracy: 0.0000e+00 - val_loss: -31966610.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -33220042.0000 - accuracy: 0.0000e+00 - val_loss: -32784820.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -34066772.0000 - accuracy: 0.0000e+00 - val_loss: -33619148.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: -34927456.0000 - accuracy: 0.0000e+00 - val_loss: -34462432.0000 - val_accuracy: 0.0000e+00\n",
      "31/31 [==============================] - 1s 7ms/step - loss: -100.0639 - accuracy: 0.0000e+00\n",
      "\n",
      "Test accuracy of the best model: 0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "wine_data = pd.read_csv(url, sep=\";\")\n",
    "\n",
    "# Separate features and target\n",
    "features = wine_data.drop(\"quality\", axis=1)  # Drop the 'quality' column\n",
    "target = wine_data[\"quality\"]\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler and fit_transform on training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a Sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Add layers to the model\n",
    "model.add(keras.layers.Input(shape=(X_train_scaled.shape[1],)))  # Input layer\n",
    "model.add(keras.layers.Dense(64, activation='relu'))  # Hidden layer 1\n",
    "model.add(keras.layers.Dense(32, activation='relu'))  # Hidden layer 2\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model with specified loss function, optimizer, and metrics\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create callbacks\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=\"./logs\", histogram_freq=1)\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True)\n",
    "\n",
    "# Fit the model with callbacks\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.2,\n",
    "                    callbacks=[tensorboard_callback, early_stopping_callback, model_checkpoint_callback])\n",
    "\n",
    "# Evaluate the best model on test data\n",
    "best_model = keras.models.load_model('best_model.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(X_test_scaled, y_test)\n",
    "print(\"\\nTest accuracy of the best model:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb465624-b9ee-46c9-8431-b67fc7822189",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, the model is fitted to the data using the model.fit() function.\n",
    "The callbacks (TensorBoard, Early Stopping, and ModelCheckpoint) are passed to\n",
    "the callbacks parameter as a list. TensorBoard will log the training process, \n",
    "Early Stopping will monitor validation loss and stop if no improvement is observed, \n",
    "and ModelCheckpoint will save the best model based on the validation accuracy.\n",
    "\n",
    "After training, the best saved model is loaded and evaluated on the test data to assess its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8081e837-c0eb-406a-a13b-57907950639c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16a9ebc-5db5-455c-991c-7e32d48b11da",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q16. Get the model's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245fd5a3-f9bd-4656-b6e0-14f66e35ef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "You can obtain the model's parameters using the get_weights() method of the layers in your Keras model.\n",
    "Here's how you can retrieve the parameters of each layer in your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dc8756b-5fb5-42b8-aaa5-1665bf671078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 parameters:\n",
      "Parameter 0: (11, 64)\n",
      "Parameter 1: (64,)\n",
      "----------------------\n",
      "Layer 1 parameters:\n",
      "Parameter 0: (64, 32)\n",
      "Parameter 1: (32,)\n",
      "----------------------\n",
      "Layer 2 parameters:\n",
      "Parameter 0: (32, 1)\n",
      "Parameter 1: (1,)\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "wine_data = pd.read_csv(url, sep=\";\")\n",
    "\n",
    "# Separate features and target\n",
    "features = wine_data.drop(\"quality\", axis=1)  # Drop the 'quality' column\n",
    "target = wine_data[\"quality\"]\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler and fit_transform on training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a Sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Add layers to the model\n",
    "model.add(keras.layers.Input(shape=(X_train_scaled.shape[1],)))  # Input layer\n",
    "model.add(keras.layers.Dense(64, activation='relu'))  # Hidden layer 1\n",
    "model.add(keras.layers.Dense(32, activation='relu'))  # Hidden layer 2\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model with specified loss function, optimizer, and metrics\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Get the model's parameters\n",
    "model_params = []\n",
    "for layer in model.layers:\n",
    "    layer_params = layer.get_weights()\n",
    "    model_params.append(layer_params)\n",
    "\n",
    "# Print the model's parameters\n",
    "for idx, params in enumerate(model_params):\n",
    "    print(f\"Layer {idx} parameters:\")\n",
    "    for i, p in enumerate(params):\n",
    "        print(f\"Parameter {i}: {p.shape}\")\n",
    "    print(\"----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a0ac99-8c52-4849-8060-bb71a6941295",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, the get_weights() method is used to retrieve the weights and\n",
    "biases of each layer in the model. The retrieved parameters are then stored in\n",
    "\n",
    "the model_params list. The code iterates through the layers and their parameters, \n",
    "printing the shape of each parameter array.\n",
    "\n",
    "Keep in mind that the output will provide you with information about the dimensions of \n",
    "weight matrices and bias vectors for each layer in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af26706-9dc3-4b68-b20a-bedd47f52b42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56d78fe-5178-45b1-a8ff-68d7cd89bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q17. Store the model's training history as a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a4954c-06d7-43f0-8fa8-9b670b363cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "You can store the model's training history as a Pandas DataFrame using the history object returned by the fit() method.\n",
    "Here's how you can do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05773d53-57ec-4dd9-9392-46647fb9ab96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1798: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "98/98 [==============================] - 4s 20ms/step - loss: -21.5073 - accuracy: 0.0000e+00 - val_loss: -69.6460 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -249.8352 - accuracy: 0.0000e+00 - val_loss: -539.7272 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -1180.1074 - accuracy: 0.0000e+00 - val_loss: -2015.8087 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -3446.5596 - accuracy: 0.0000e+00 - val_loss: -5095.4160 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 1s 7ms/step - loss: -7626.1973 - accuracy: 0.0000e+00 - val_loss: -10325.7139 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -14241.0859 - accuracy: 0.0000e+00 - val_loss: -18144.0859 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 1s 7ms/step - loss: -23726.7871 - accuracy: 0.0000e+00 - val_loss: -29015.9082 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -36487.0039 - accuracy: 0.0000e+00 - val_loss: -43260.2188 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 1s 7ms/step - loss: -52919.2695 - accuracy: 0.0000e+00 - val_loss: -61243.0938 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 1s 7ms/step - loss: -73306.5859 - accuracy: 0.0000e+00 - val_loss: -83231.1562 - val_accuracy: 0.0000e+00\n",
      "          loss  accuracy      val_loss  val_accuracy\n",
      "0   -21.507267       0.0    -69.645988           0.0\n",
      "1  -249.835220       0.0   -539.727173           0.0\n",
      "2 -1180.107422       0.0  -2015.808716           0.0\n",
      "3 -3446.559570       0.0  -5095.416016           0.0\n",
      "4 -7626.197266       0.0 -10325.713867           0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "wine_data = pd.read_csv(url, sep=\";\")\n",
    "\n",
    "# Separate features and target\n",
    "features = wine_data.drop(\"quality\", axis=1)  # Drop the 'quality' column\n",
    "target = wine_data[\"quality\"]\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler and fit_transform on training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a Sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Add layers to the model\n",
    "model.add(keras.layers.Input(shape=(X_train_scaled.shape[1],)))  # Input layer\n",
    "model.add(keras.layers.Dense(64, activation='relu'))  # Hidden layer 1\n",
    "model.add(keras.layers.Dense(32, activation='relu'))  # Hidden layer 2\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model with specified loss function, optimizer, and metrics\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model and store training history\n",
    "history = model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Convert the training history to a Pandas DataFrame\n",
    "history_df = pd.DataFrame(history.history)\n",
    "\n",
    "# Print the first few rows of the history DataFrame\n",
    "print(history_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d03655-e86a-4665-b221-e6c69c621b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, the history object returned by the fit() method contains the training history\n",
    "including loss and metrics values for each epoch. We convert this history dictionary into a\n",
    "Pandas DataFrame using pd.DataFrame(history.history).\n",
    "\n",
    "The resulting history_df DataFrame will have columns for training loss, training accuracy,\n",
    "validation loss, and validation accuracy for each epoch. You can further analyze and visualize\n",
    "this DataFrame using Pandas and plotting libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc5b483-378c-4aa6-b729-ae82c91135f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733094ae-21c4-4fea-8722-6903ec51dfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q18. Plot the model's training history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c51a15a-a924-4b0c-9cea-4e70f8bcca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "To plot the model's training history, you can use the training history stored in the \n",
    "\n",
    "Pandas DataFrame and visualize it using libraries like Matplotlib or Seaborn. \n",
    "Here's an example using Matplotlib to plot the training and validation loss and accuracy over epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bba646e-7b7f-4f69-a940-49bf21a4235a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1798: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "98/98 [==============================] - 3s 18ms/step - loss: -20.9117 - accuracy: 0.0000e+00 - val_loss: -62.9582 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -213.6840 - accuracy: 0.0000e+00 - val_loss: -461.4191 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 1s 7ms/step - loss: -1018.9053 - accuracy: 0.0000e+00 - val_loss: -1751.9910 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 1s 7ms/step - loss: -3018.7981 - accuracy: 0.0000e+00 - val_loss: -4506.3057 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 1s 7ms/step - loss: -6739.0630 - accuracy: 0.0000e+00 - val_loss: -9176.3418 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 1s 10ms/step - loss: -12665.9590 - accuracy: 0.0000e+00 - val_loss: -16257.4053 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -21250.8418 - accuracy: 0.0000e+00 - val_loss: -26110.4648 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -32827.8828 - accuracy: 0.0000e+00 - val_loss: -39119.6797 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -47767.4531 - accuracy: 0.0000e+00 - val_loss: -55557.5156 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -66363.2031 - accuracy: 0.0000e+00 - val_loss: -75711.3281 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "wine_data = pd.read_csv(url, sep=\";\")\n",
    "\n",
    "# Separate features and target\n",
    "features = wine_data.drop(\"quality\", axis=1)  # Drop the 'quality' column\n",
    "target = wine_data[\"quality\"]\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler and fit_transform on training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a Sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Add layers to the model\n",
    "model.add(keras.layers.Input(shape=(X_train_scaled.shape[1],)))  # Input layer\n",
    "model.add(keras.layers.Dense(64, activation='relu'))  # Hidden layer 1\n",
    "model.add(keras.layers.Dense(32, activation='relu'))  # Hidden layer 2\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model with specified loss function, optimizer, and metrics\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model and store training history\n",
    "history = model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Convert the training history to a Pandas DataFrame\n",
    "history_df = pd.DataFrame(history.history)\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot training & validation loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_df['loss'], label='Training Loss')\n",
    "plt.plot(history_df['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training & validation accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_df['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_df['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training & Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64a16c3-f4a1-4cff-a6ad-525b1614dd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, we're using Matplotlib to create a figure with two subplots. In the left subplot,\n",
    "we're plotting the training and validation loss over epochs, and in the right subplot,\n",
    "we're plotting the training and validation accuracy over epochs. The training history stored\n",
    "in the history_df DataFrame is used for plotting. The plt.show() function displays the plots.\n",
    "\n",
    "Feel free to modify the code to adjust the plot settings or incorporate other visualization\n",
    "libraries like Seaborn for a different visual style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febdc37e-6701-477a-bd3a-a6e2f9ae98a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd8e585-6fda-4028-9a12-7c1771eefb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q19. Evaluate the model's performance using the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9621a72c-6f05-4ae9-9699-2e99707afcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Certainly! To evaluate the model's performance using the test data, you can use the evaluate() \n",
    "method of the trained model. This method will give you the test loss and test accuracy.\n",
    "Here's how you can do it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10ce1611-47da-404d-9d47-af8e49c88414",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1798: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "98/98 [==============================] - 2s 12ms/step - loss: -35.1971 - accuracy: 0.0000e+00 - val_loss: -107.5830 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 1s 7ms/step - loss: -363.7892 - accuracy: 0.0000e+00 - val_loss: -765.1588 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 1s 6ms/step - loss: -1613.7600 - accuracy: 0.0000e+00 - val_loss: -2711.2646 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 1s 7ms/step - loss: -4570.1191 - accuracy: 0.0000e+00 - val_loss: -6700.8813 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 1s 6ms/step - loss: -9945.9355 - accuracy: 0.0000e+00 - val_loss: -13371.5557 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 1s 7ms/step - loss: -18343.8477 - accuracy: 0.0000e+00 - val_loss: -23279.4180 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 1s 9ms/step - loss: -30369.5820 - accuracy: 0.0000e+00 - val_loss: -37016.5430 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 1s 6ms/step - loss: -46544.8516 - accuracy: 0.0000e+00 - val_loss: -55051.1484 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 1s 8ms/step - loss: -67301.2891 - accuracy: 0.0000e+00 - val_loss: -77733.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 1s 7ms/step - loss: -93059.6875 - accuracy: 0.0000e+00 - val_loss: -105498.4609 - val_accuracy: 0.0000e+00\n",
      "31/31 [==============================] - 0s 7ms/step - loss: -108315.7422 - accuracy: 0.0000e+00\n",
      "\n",
      "Test loss: -108315.7421875\n",
      "Test accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "wine_data = pd.read_csv(url, sep=\";\")\n",
    "\n",
    "# Separate features and target\n",
    "features = wine_data.drop(\"quality\", axis=1)  # Drop the 'quality' column\n",
    "target = wine_data[\"quality\"]\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler and fit_transform on training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a Sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Add layers to the model\n",
    "model.add(keras.layers.Input(shape=(X_train_scaled.shape[1],)))  # Input layer\n",
    "model.add(keras.layers.Dense(64, activation='relu'))  # Hidden layer 1\n",
    "model.add(keras.layers.Dense(32, activation='relu'))  # Hidden layer 2\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model with specified loss function, optimizer, and metrics\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"\\nTest loss:\", test_loss)\n",
    "print(\"Test accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0ad8a2-4924-4a85-9b6b-0e8ee8f28020",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, after training the model using the training data, the evaluate() \n",
    "method is used to assess the model's performance on the test data. The test_loss\n",
    "variable will hold the test loss value, and the test_accuracy variable will hold \n",
    "the test accuracy value. These values give you an indication of how well the trained model performs on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7702181a-6e21-48d1-974e-f64bf6a70df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "......................................The End..............................."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
